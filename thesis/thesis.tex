\documentclass{amsart}

\usepackage{amssymb}

\usepackage[utf8]{inputenc}

\usepackage[
  backend=biber,
  natbib=true
]{biblatex}

\bibliography{thesis}

\usepackage{tabularx}
\newcolumntype{Y}{>{\centering\arraybackslash}X}

\usepackage{todonotes}

\usepackage{hyperref}
\usepackage[german,english]{babel}

\usepackage{listings}
\renewcommand{\lstlistingname}{Algorithm}

\usepackage{enumerate}

\usepackage{cleveref}
\crefname{section}{\S}{\S\S}
\Crefname{section}{\S}{\S\S}

\usepackage{csquotes}
\setquotestyle{american}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{xca}[section]{Exercise}
\newtheorem*{ans}{Answer}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\DeclareMathOperator{\LCM}{LCM}

\numberwithin{equation}{section}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title Page
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\def\thetitle{On The Rank of a Polynomial Matrix}
\def\theauthor{Patrick McLaren}
\def\theemail{patrick.mclaren001@umb.edu}

\begin{titlepage}
  \begin{center}
    \textsc{\LARGE \thetitle}\\[0.75cm]
    \textsc{By}\\[0.25cm]
    \textsc{\large \theauthor}\\[1cm]
  \end{center}
\end{titlepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Abstract
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\thispagestyle{empty}

\section*{Abstract}

\begin{center}
  \begin{minipage}{0.8\textwidth}
    \small
    \begin{flushleft}
      The abstract goes here.
    \end{flushleft}
  \end{minipage}
\end{center}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Main Content
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\thispagestyle{empty}

\section*{Plan}

\subsection*{Overview}

\begin{enumerate}
\item Statement of problem, motivating example, and outline of methods
\item Recall basic definitions and theorems of linear algebra including Gaussian Elimination
\item Introduce polynomial rings, ideals, and gr\"oebner bases (along with all prerequisites, cf. Hilbert Basis Theorem, noetherian rings, A.C.C)
\item Introduce modules, free modules, finite presentations
\item Discuss row reducing a polynomial matrix (presentation matrix)
\item Discuss conditions a matrix has rank $m \leq n$
\end{enumerate}

\subsection*{Potential References}

I've noted a sharp drop in the number of accessible resources regarding modules over a polynomial ring in several variables, in contrast to the single variable case. Here's a list of references I have recently viewed. I may temporarily block-quote these references for easy viewing in \cref{sec:notes-from-sources}.

\subsubsection*{Module over a Polynomial Ring of Single Variable}

\begin{itemize}
\item \fullcite{artin2014algebra}
\end{itemize}

\subsubsection*{Module over a Polynomial Ring of Several Variables}

\begin{itemize}
\item \fullcite{cox2007ideals}
\end{itemize}

\subsubsection*{Other}

\begin{itemize}
\item \fullcite{bruns}
\end{itemize}

\newpage

\setcounter{page}{1}

\section{Introduction}

A polynomial matrix is a linear operator on a module over a polynomial ring. The rank of a linear operator on a module is not well defined, however given a polynomial matrix, we can evaluate it's entries on $s \in F$ to produce a matrix $A(s)$ on a vector space. Then, we can proceed to determine the rank of $A(s)$.

The situation is slightly different if one does not immediately wish to obtain $A(s)$. Perhaps we would like to know about the conditions for which the matrix fails to have rank $m$. Suppose that by manipulating $A$, we can produce a row-reduced echelon form of $A$, say $A'$, such that $\mathrm{rank}\,A(s) = \mathrm{rank}\,A'(s)$. Then, one may examine the pivots to determine the rank. However, this leads to several problems:

\begin{enumerate}
\item As we manipulate the matrix $A$, we may assume that a given entry $(i,i)$ will be non-zero in $A'(s)$, as shown in \cref{fig:pivot-example}.
\begin{figure}[h]
  \centering
  \begin{align*}
    \begin{bmatrix}
      f_1 & \dots & \dots & \dots \\
      \hdotsfor{4} \\
      f_i & \dots & \dots & \dots \\
      \hdotsfor{4}
    \end{bmatrix} & \overset{\text{pivot by } f_1}{\to} \begin{bmatrix}
      1 & \dots & \dots & \dots \\
      \hdotsfor{4} \\
      0 & \dots & \dots & \dots \\
      \hdotsfor{4}
    \end{bmatrix}
  \end{align*}
  \caption{Assuming $f_1(s) \not= 0$}
  \label{fig:pivot-example}
\end{figure}

Rather than selecting pivots which are not equal to the zero-polynomial, our method should consider the possibility that $a_{i,i}(s) = 0$ for some $s \in F$.

\item Pivoting in the traditional manner using Gaussian Eliminiation (i.e. $a_{i,i} \mapsto 1$) produces a block matrix as shown in \cref{fig:gaussian-eliminiation-example}. In this case, by the conclusion of the algorithm, all information regarding the pivots has been lost.
\begin{figure}[h]
  \centering
  \begin{equation*}
    \left[
    \begin{array}{c | c c }
      \raisebox{0pt}{{\large\mbox{{$I$}}}} & \dots & 0 \\ \hline
      \vdots & \ddots & \vdots \\
      0 & \dots & 0
    \end{array}
    \right]
  \end{equation*}
  \caption{Output of Gaussian Elimination}
  \label{fig:gaussian-eliminiation-example}
\end{figure}

\item Depending on our choice of pivots, we could potentially produce multiple matrices $A', A'', \ldots$ from $A$ with the property $\mathrm{rank} \, A'(s) = \mathrm{rank} \, A''(s) = \cdots = \mathrm{rank} \, A(s)$. Given a collection of pivots, say $P', P''$, from $A', A''$, we would like some nice way of comparing $P'$ and $P''$.

\end{enumerate}

\subsection{Outline of Method}

For every pivot $a_{i,i}$ that we choose to be non-zero, we must also take into account the possibility that $a_{i,i}(s) = 0$ for some $s \in F$, potentially producing $n!$ different matrices.

Every row-reduced matrix $A'$ that we produce has an associated collection of pivots which are assumed to be non-zero $P = (a_{i,i})_{i \in \Lambda}$, and a collection of entries which are assumed to be zero $Q = (a_{i,j})_{i \in \Delta}$. In this case, $q \nmid p$ for all $q \in Q, p \in P$. Equivalently, the elements of $P$ are elements of the quotient ring $F[X]/I$, where $I = \langle Q \rangle$.

\section{Preliminaries}
\label{sec:preliminaries}

\subsection{Review of Linear Algebra}

\subsubsection{Vector Spaces}

\begin{definition}
    Let $F$ be a field. Let $V$ be a subset of $F$, and suppose that $V$
    satisfies the following properties
    \begin{enumerate}[i]
        \item $v_1, v_2 \in V \implies v_1 + v_2 \in V$
        \item $v_1 \in V, c \in F \implies c * v_1 \in V$
    \end{enumerate}
    In this case, $V$ is said to be a \emph{vector space} over $F$.
\end{definition}

\subsubsection{Matrix Representation of a Linear Transformation}

\subsubsection{Row Echelon Form}

The setting in which one wants to produce an upper triangular matrix usually involves some desire to solve the equation
\begin{equation*}
  AX = B
\end{equation*}
where $A$ is an invertible linear transformation, and $X, B$ are vectors (or elements of a free module). One can perform \emph{Gaussian Elimination} to produce an upper triangular matrix (or \emph{Gauss-Jordan Elimination} to produce the reduced row echelon form of a matrix) by applying a sequence of elementary row operations to the system. \\

Now, these elementary row operations can be represented as elementary matrices, say $E_1, \ldots, E_k$. Applied to the original system, we have
\begin{align*}
  E_k \cdots E_1 AX &= E_k \cdots E_1 B\\
  A'X &= B'
\end{align*}

We know that these operations do not change the solution to the equation by application of the cancellation law, since elementary matrices are invertible. Then, one may obtain $X$ by back-substitution. If $A$ was not invertible, then a pseudoinverse may be obtained to describe all solutions that satisfy the equation.

\section{Rings}
\label{seq:rings}

\subsection{Definitions}

\subsection{Polynomial Rings}

\subsection{Ideals}

\begin{definition}
  Let $R[X]$ be a polynomial ring, and let $I \subset R$. Suppose that $I$ satisfies the following properties:
  \begin{enumerate}[i]
  \item $0 \in I$
  \item If $f, g \in I$, then $f + g \in I$
  \item If $f \in I, h \in R$, then $hf \in I$
  \end{enumerate}
  In this case, $I$ is said to be an \emph{ideal}.
\end{definition}

\begin{definition}
  Let $R[X]$ be as above, and let $f_1, \ldots, f_n$ be polynomials in $R[X]$. We define
  \begin{equation*}
    \langle f_1, \ldots f_n \rangle = \left\{ \sum_{i = 1}^n h_i f_i \mid h_1, \ldots, h_n \in R[X] \right\}
  \end{equation*}
\end{definition}

Given polynomials $f_1, \ldots, f_n$, it is easy to see that $\langle f_1, \ldots, f_n \rangle$ is an ideal. Indeed, $h_1 = h_2 = \cdots = h_n = 0$, then $\sum h_i f_i = 0$, so $0 \in \langle f_1, \ldots, f_n \rangle$. For $f_j, f_k \in \{ f_1, \ldots, f_n \}$, set $h_i$ equal to $1$ if $i = j$ or $k$, and $0$ otherwise, so $f_j + f_k \in \langle f_1, \ldots, f_n \rangle$. For $f_k \in \{ f_1, \ldots, f_n \}$, set $h_i = c$ if $i = k$, and $0$ otherwise, so $c f_k \in \langle f_1, \ldots, f_n \rangle$. So, $\langle f_1, \ldots, f_n \rangle$ is an ideal in $R[X]$, namely, the \emph{ideal generated by $f_1, \ldots, f_n$}.

\leavevmode

\todo[inline]{Hilbert Basis Theorem}

\leavevmode

\todo[inline]{Noetherian Rings}

\subsection{Gr\"oebner Bases}

\todo{Paraphrase this - copied from Cox, Little \& O'Shea}
\begin{definition}
  Fix a monomial order. A finite subset $G = \{ g_1, \ldots, g_t \}$ of an ideal $I$ is said to be a \emph{Gr\"oebner basis} if
  \begin{equation*}
    \langle \mathrm{LT}(g_1), \ldots, \mathrm{LT(g_n)} \rangle = \langle \mathrm{LT}(I) \rangle
  \end{equation*}
\end{definition}

\todo[inline]{Uniqueness of a reduced Gr\"oebner basis}

\section{Modules}
\label{sec:modules}

\subsection{Definitions}

\begin{definition}
  Let $R$ be a ring, then a \emph{left $R$-module} or a \emph{left module over $R$} is an abelian group $V$ together an action on $R$ that satisfies the following properties
  \begin{enumerate}[i]
  \item $(r + s)v = rv + sv$, for all $r, s \in R, v \in V$
  \item $(rs)v = r(sv)$, for all $r, s \in R, v \in V$
  \item $r(v + w) = rv + rw$, for all $r \in R, v, w \in V$
  \end{enumerate}
\end{definition}

\subsection{Module over a Polynomial Ring}

\leavevmode \\

\todo[inline]{Basic Definitions}

\subsection{Presentation Matrix of a Module}

\leavevmode \\

\todo[inline]{Matrix operations that don't change the isomorphism class of a presentation matrix}

\subsection{Row Echelon Form of a Polynomial Matrix}

\begin{lstlisting}[caption=Computing the Row Echelon Form of a Polynomial Matrix]
    max_pivots = min(row_size, column_size)
    for i in (1 ... max_pivots):
        for j in (1 ... max_pivots):
            if i == j:
                continue

            target_lcm = lcm(matrix[i][i], matrix[j][i])
    
            pivot_quotient = target_lcm / matrix[i][i]
            clear_quotient = target_lcm / matrix[j][i]
    
            matrix.scala_mult(clear_quotient, j)
            matrix.subtract_row(pivot_quotient, i, j)
\end{lstlisting}

\section{When does a Polynomial Matrix have Rank $\leq$ n?}
\label{sec:polynomial-matrix}

\section{Examples}

\section{Conclusion}

\newpage

\section*{Notes from sources}
\label{sec:notes-from-sources}

\blockquote[S. Lang, Algebra, pg. 138]{It will be proved in the next section that a vector space over a field is always free, i.e. has a basis. Under certain circumstances, it is a theorem that projective modules are free. In \S 7 we shall prove that a finitely generated projective module over a principle ring is free. In Chapter X, Theorem 4.4 we shall prove that such a module over a local ring is free; in Chapter XVI, Theorem 3.8 we shall prove that a finite flat module over a local ring is free; and in Chapter XXI, Theorem 3.7, we shall prove the Quillen-Suslin theorem that if $A = k[X_1, \ldots, X_n]$ is the polynomial ring over a field $k$, then every finite projective module over $A$ is free.}

\newpage

\section*{Appendix}

\subsection*{Source Code}

\leavevmode \\

\todo[inline]{Include relevant code without inline documentation from https://github.com/patrickmclaren/math-thesis}

\subsection*{Code Documentation}

\leavevmode \\

\todo[inline]{Include documentation (ensure short and unstyled) from https://github.com/patrickmclaren/polyrank-docs}

\newpage

\printbibliography

\end{document}